{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13907742,"sourceType":"datasetVersion","datasetId":8861279}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implémentation","metadata":{}},{"cell_type":"markdown","source":"### 1. Installation des bibliothèques","metadata":{}},{"cell_type":"code","source":"!pip install -U langchain langchain-community langchain-core \\\nlangchain-text-splitters sentence-transformers transformers pypdf accelerate bitsandbytes\n\n!pip install chromadb==0.4.24\n\n!pip install --force-reinstall protobuf==3.20.3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:42:57.084328Z","iopub.execute_input":"2025-11-28T15:42:57.084880Z","iopub.status.idle":"2025-11-28T15:44:53.646033Z","shell.execute_reply.started":"2025-11-28T15:42:57.084856Z","shell.execute_reply":"2025-11-28T15:44:53.645274Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\nCollecting langchain\n  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting langchain-community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.72)\nCollecting langchain-core\n  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.9)\nCollecting langchain-text-splitters\n  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting sentence-transformers\n  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nCollecting transformers\n  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (6.1.3)\nCollecting pypdf\n  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nCollecting langgraph<1.1.0,>=1.0.2 (from langchain)\n  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.12.4)\nCollecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (25.0)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.15.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\nCollecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\nCollecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\nCollecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n  Downloading langgraph_sdk-0.2.10-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\nCollecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n  Downloading ormsgpack-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain-1.1.0-py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\nDownloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph-1.0.4-py3-none-any.whl (157 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\nDownloading langgraph_sdk-0.2.10-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ormsgpack-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pypdf, ormsgpack, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langgraph-prebuilt, langchain-classic, langgraph, langchain, transformers, sentence-transformers, langchain-community, bitsandbytes, accelerate\n  Attempting uninstall: pypdf\n    Found existing installation: pypdf 6.1.3\n    Uninstalling pypdf-6.1.3:\n      Successfully uninstalled pypdf-6.1.3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.72\n    Uninstalling langchain-core-0.3.72:\n      Successfully uninstalled langchain-core-0.3.72\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.9\n    Uninstalling langchain-text-splitters-0.3.9:\n      Successfully uninstalled langchain-text-splitters-0.3.9\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.27\n    Uninstalling langchain-0.3.27:\n      Successfully uninstalled langchain-0.3.27\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 4.1.0\n    Uninstalling sentence-transformers-4.1.0:\n      Successfully uninstalled sentence-transformers-4.1.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.9.0\n    Uninstalling accelerate-1.9.0:\n      Successfully uninstalled accelerate-1.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.48.2 langchain-1.1.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.0 langchain-text-splitters-1.0.0 langgraph-1.0.4 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ormsgpack-1.12.0 pypdf-6.4.0 sentence-transformers-5.1.2 tokenizers-0.22.1 transformers-4.57.3\nCollecting chromadb==0.4.24\n  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.2.2.post1)\nRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (2.32.5)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (2.12.4)\nCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.24)\n  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nRequirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (0.116.1)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.35.0)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.26.4)\nCollecting posthog>=2.4.0 (from chromadb==0.4.24)\n  Downloading posthog-7.0.1-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (4.15.0)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.24)\n  Downloading pulsar_client-3.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.24)\n  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.37.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.4.24)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.4.24)\n  Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (0.22.1)\nCollecting pypika>=0.48.9 (from chromadb==0.4.24)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (1.74.0)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.24)\n  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (0.16.0)\nCollecting kubernetes>=28.1.0 (from chromadb==0.4.24)\n  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (9.1.2)\nRequirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (6.0.3)\nCollecting mmh3>=4.0.1 (from chromadb==0.4.24)\n  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.24) (3.11.0)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.4.24) (25.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.4.24) (1.2.0)\nRequirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb==0.4.24) (0.47.2)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2025.10.5)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.0.0)\nCollecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb==0.4.24)\n  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.4.24)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb==0.4.24) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.24)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (6.33.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.24) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24)\n  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb==0.4.24)\n  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\nCollecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading opentelemetry_util_http-0.59b0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (1.17.2)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.59b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24)\n  Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb==0.4.24)\n  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.24)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.4.24) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.4.24) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.4.24) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.4.24) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28->chromadb==0.4.24) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28->chromadb==0.4.24) (3.11)\nRequirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb==0.4.24) (0.36.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.24) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.24) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.24) (14.2.0)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.16.0)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (1.2.1)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.24)\n  Downloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (15.0.1)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (4.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.24) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.24) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.24) (1.2.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.24) (3.23.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.24) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.24) (2.19.2)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.24) (4.11.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.24)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb==0.4.24) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb==0.4.24) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb==0.4.24) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb==0.4.24) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb==0.4.24) (2024.2.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==0.4.24) (3.3.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.24) (1.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.24) (1.3.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb==0.4.24) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.24) (0.1.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.6.1)\nDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl (13 kB)\nDownloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\nDownloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl (16 kB)\nDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_util_http-0.59b0-py3-none-any.whl (7.6 kB)\nDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-7.0.1-py3-none-any.whl (145 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.6/456.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading asgiref-3.11.0-py3-none-any.whl (24 kB)\nDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=355eef43a727615d479f0c3ae56e163cabbdb81a4bb0e5fbe7fd19fef372736f\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, urllib3, pulsar-client, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, cachetools, bcrypt, backoff, asgiref, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-instrumentation, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, onnxruntime, chroma-hnswlib, chromadb\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.5.0\n    Uninstalling urllib3-2.5.0:\n      Successfully uninstalled urllib3-2.5.0\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.37.0\n    Uninstalling opentelemetry-proto-1.37.0:\n      Successfully uninstalled opentelemetry-proto-1.37.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.37.0\n    Uninstalling opentelemetry-api-1.37.0:\n      Successfully uninstalled opentelemetry-api-1.37.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.37.0\n    Uninstalling opentelemetry-sdk-1.37.0:\n      Successfully uninstalled opentelemetry-sdk-1.37.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-adk 1.18.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.11.0 backoff-2.2.1 bcrypt-5.0.0 cachetools-5.5.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-asgi-0.59b0 opentelemetry-instrumentation-fastapi-0.59b0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opentelemetry-util-http-0.59b0 posthog-7.0.1 pulsar-client-3.8.0 pypika-0.48.9 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\nCollecting protobuf==3.20.3\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.38.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 2. Chargement des bibliothèques","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\n\n# LangChain\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import Chroma\n\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\n# Transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline as hf_pipeline\nfrom langchain_community.llms import HuggingFacePipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:45:00.558814Z","iopub.execute_input":"2025-11-28T15:45:00.559607Z","iopub.status.idle":"2025-11-28T15:45:36.248714Z","shell.execute_reply.started":"2025-11-28T15:45:00.559577Z","shell.execute_reply":"2025-11-28T15:45:36.248068Z"}},"outputs":[{"name":"stderr","text":"2025-11-28 15:45:10.614183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764344710.840588      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764344710.904517      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 3. CHARGEMENT DES PDF","metadata":{}},{"cell_type":"code","source":"def load_pdfs(pdf_paths):\n    \"\"\"\n    Charge plusieurs fichiers PDF et renvoie une liste de Documents.\n    Chaque page du PDF devient un Document (page_content + metadata).\n    \"\"\"\n    all_docs = []\n    for path in pdf_paths:\n        if not os.path.exists(path):\n            raise FileNotFoundError(f\"Fichier introuvable : {path}\")\n        print(f\" - Chargement du PDF : {path}\")\n        loader = PyPDFLoader(path)\n        docs = loader.load()\n        print(f\"   {len(docs)} pages chargées\")\n        all_docs.extend(docs)\n\n    print(f\"\\nTotal : {len(all_docs)} pages sur l'ensemble des PDF\\n\")\n    return all_docs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:45:48.534088Z","iopub.execute_input":"2025-11-28T15:45:48.534885Z","iopub.status.idle":"2025-11-28T15:45:48.540049Z","shell.execute_reply.started":"2025-11-28T15:45:48.534856Z","shell.execute_reply":"2025-11-28T15:45:48.539071Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 4. DÉCOUPAGE EN CHUNKS","metadata":{}},{"cell_type":"code","source":"def split_documents(docs):\n    \"\"\"\n    Découpe les Documents (pages PDF) en chunks plus petits.\n    \"\"\"\n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=800,      # taille max d'un chunk en caractères\n        chunk_overlap=200    # recouvrement entre chunks\n    )\n    chunks = splitter.split_documents(docs)\n    print(f\"{len(chunks)} chunks créés après découpage\")\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:45:52.387725Z","iopub.execute_input":"2025-11-28T15:45:52.388280Z","iopub.status.idle":"2025-11-28T15:45:52.392450Z","shell.execute_reply.started":"2025-11-28T15:45:52.388253Z","shell.execute_reply":"2025-11-28T15:45:52.391577Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### 5. EMBEDDINGS + CHROMA","metadata":{}},{"cell_type":"code","source":"def build_vectorstore(chunks, persist_directory: str = \"chroma_pdf_db\"):\n    \"\"\"\n    Crée une base vectorielle Chroma à partir des chunks.\n    Utilise des embeddings SentenceTransformers.\n    \"\"\"\n    print(\"Construction de la base vectorielle (embeddings Chroma)...\")\n\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n    )\n\n    vectorstore = Chroma.from_documents(\n        documents=chunks,\n        embedding=embeddings,\n        persist_directory=persist_directory\n    )\n\n    print(\"Vectorstore prête\\n\")\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:45:56.308654Z","iopub.execute_input":"2025-11-28T15:45:56.309427Z","iopub.status.idle":"2025-11-28T15:45:56.313847Z","shell.execute_reply.started":"2025-11-28T15:45:56.309382Z","shell.execute_reply":"2025-11-28T15:45:56.313128Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### 6. PROMPT RAG TRÈS STRICT","metadata":{}},{"cell_type":"code","source":"RAG_PROMPT_TEMPLATE = \"\"\"\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MÊME langue que la QUESTION\n   (si la question est en français alors réponse en français,\n   si elle est en anglais alors réponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l'information n'est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\n{context}\nQUESTION DE L'UTILISATEUR :\n{question}\n\nRÉPONSE (une seule langue, celle de la question) :\n\"\"\"\n\ndef build_prompt():\n    return PromptTemplate(\n        input_variables=[\"context\", \"question\"],\n        template=RAG_PROMPT_TEMPLATE\n    )\n\ndef format_docs(docs):\n    \"\"\"\n    Concatène le contenu des Documents en une seule chaîne de contexte.\n    \"\"\"\n    return \"\\n\\n\".join(doc.page_content for doc in docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:46:00.751379Z","iopub.execute_input":"2025-11-28T15:46:00.752144Z","iopub.status.idle":"2025-11-28T15:46:00.756782Z","shell.execute_reply.started":"2025-11-28T15:46:00.752118Z","shell.execute_reply":"2025-11-28T15:46:00.755931Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### 7. LLM OPEN SOURCE FORT : Qwen2.5-7B-Instruct","metadata":{}},{"cell_type":"code","source":"def build_llm(model_name: str = \"Qwen/Qwen2.5-7B-Instruct\"):\n    \"\"\"\n    Construit un LLM open source (Qwen2.5-7B-Instruct) via Transformers.\n    Nécessite une machine GPU performante.\n    \"\"\"\n    print(f\"Chargement du modèle : {model_name}...\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16\n    )\n\n    text_gen = hf_pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=256,\n        do_sample=False,\n        repetition_penalty=1.05\n    )\n\n    llm = HuggingFacePipeline(pipeline=text_gen)\n    print(\"LLM Qwen2.5-7B prêt\\n\")\n    return llm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:46:06.532671Z","iopub.execute_input":"2025-11-28T15:46:06.533158Z","iopub.status.idle":"2025-11-28T15:46:06.538043Z","shell.execute_reply.started":"2025-11-28T15:46:06.533133Z","shell.execute_reply":"2025-11-28T15:46:06.537260Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### 8. CHAÎNE RAG (LCEL)","metadata":{}},{"cell_type":"code","source":"def build_rag_chain(vectorstore, llm):\n    \"\"\"\n    Construit une chaîne RAG :\n    question -> retriever -> formatage du contexte -> prompt -> LLM\n    \"\"\"\n    retriever = vectorstore.as_retriever(\n        search_type=\"similarity\",\n        search_kwargs={\"k\": 4}  # nombre de chunks récupérés\n    )\n\n    prompt = build_prompt()\n\n    rag_chain = {\n        \"context\": retriever | format_docs,\n        \"question\": RunnablePassthrough()\n    } | prompt | llm\n\n    return rag_chain\n\n\ndef answer_question(rag_chain, question: str) -> str:\n    \"\"\"\n    Appelle la chaîne RAG sur une question donnée.\n    \"\"\"\n    return rag_chain.invoke(question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:46:10.396230Z","iopub.execute_input":"2025-11-28T15:46:10.396546Z","iopub.status.idle":"2025-11-28T15:46:10.401625Z","shell.execute_reply.started":"2025-11-28T15:46:10.396523Z","shell.execute_reply":"2025-11-28T15:46:10.400900Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### 9. MAIN","metadata":{}},{"cell_type":"code","source":"# MAIN\nprint(\"=== RAG LangChain + Qwen2.5-7B-Instruct + 2 PDF ===\\n\")\n\n# 1) Charger les PDF\nPDF_PATHS = [\"/kaggle/input/tp-rag-dataset/Chapitre1.pdf\", \"/kaggle/input/tp-rag-dataset/Chapitre2.pdf\"]\ndocs = load_pdfs(PDF_PATHS)\n\n# 2) Découper en chunks\nchunks = split_documents(docs)\n\n# 3) Construire la base vectorielle\nvectorstore = build_vectorstore(chunks)\n\n# 4) LLM\nllm = build_llm()\n\n# 5) Chaîne RAG\nrag_chain = build_rag_chain(vectorstore, llm)\n\nprint(\"Tes deux PDF sont indexés.\")\nprint(\"Tape 'exit' pour quitter.\\n\")\n\nwhile True:\n    try:\n        question = input(\">>> Question : \").strip()\n        if question.lower() in {\"exit\", \"quit\"}:\n            print(\"Au revoir\")\n            break\n\n        if not question:\n            continue\n\n        print(\"\\n[Assistant] Réponse en cours...\\n\")\n        try:\n            response = answer_question(rag_chain, question)\n            print(response)\n            print(\"\\n\" + \"-\" * 60 + \"\\n\")\n        except Exception as e:\n            print(\"Erreur lors de la génération de la réponse :\", e)\n            print(\"\\n\" + \"-\" * 60 + \"\\n\")\n\n    except (EOFError, KeyboardInterrupt):\n        print(\"\\nAu revoir\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:46:14.325605Z","iopub.execute_input":"2025-11-28T15:46:14.326121Z"}},"outputs":[{"name":"stdout","text":"=== RAG LangChain + Qwen2.5-7B-Instruct + 2 PDF ===\n\n - Chargement du PDF : /kaggle/input/tp-rag-dataset/Chapitre1.pdf\n   35 pages chargées\n - Chargement du PDF : /kaggle/input/tp-rag-dataset/Chapitre2.pdf\n   44 pages chargées\n\nTotal : 79 pages sur l'ensemble des PDF\n\n82 chunks créés après découpage\nConstruction de la base vectorielle (embeddings Chroma)...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/228020668.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n  embeddings = HuggingFaceEmbeddings(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d48ae320a8704c1f9ce018965d8f8e75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe5597a6ed84b8db1275b731f831b54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2d75795886246a5bcc6c68e3207d4e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a614406a8c4619a138079da03b676d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"174774a7ebd544509ddc66499e6a491b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35dd9f27c89044da8f706eba5a2dd4d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb84c6da77f4c5f846c29a25d523ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42039514c73e4b698fdbff9e1701b833"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba66b831714c42c1b1275117d02ec50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbae077c837e470291f85dcdd2e91226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4145a7ea13645799a097ab01e70ffb3"}},"metadata":{}},{"name":"stderr","text":"ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\nERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n","output_type":"stream"},{"name":"stdout","text":"Vectorstore prête\n\nChargement du modèle : Qwen/Qwen2.5-7B-Instruct...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3cbb6b3073e41f39288936e5b4a32d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0deb01b6ba4748928e70359487306fdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fc790598bf49e491ab88931bff3d7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aac0086e8ef2498790519d2ae12dcf27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef1ff985e2d84b388759cb70e75c56c5"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ee10ebe167d4c4190c44153f86da1fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17bd87e1691441eab415be2f1a1835e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9a2aca8dd7488086c5a4dccfe8b059"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e120579f7064d73a8074c9e9735339b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2e1ccb29cb44a0fad7ded13ff1fb0b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1819b99e6b544d9a7e1ddb084ea5640"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb80719f88e4b25917cb5bddf71ae7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82a8c16980504bdebb1b40fd4d6f69f5"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n/tmp/ipykernel_47/3165375012.py:25: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=text_gen)\n","output_type":"stream"},{"name":"stdout","text":"LLM Qwen2.5-7B prêt\n\nTes deux PDF sont indexés.\nTape 'exit' pour quitter.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":">>> Question :  quel est le nom du professeur ?\n"},{"name":"stderr","text":"ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n","output_type":"stream"},{"name":"stdout","text":"\n[Assistant] Réponse en cours...\n\n\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MÊME langue que la QUESTION\n   (si la question est en français alors réponse en français,\n   si elle est en anglais alors réponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l'information n'est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\n38\nTransformersAttention\nCréer de nouveaux embeddings en modifiant ceux qui existent \ndéjà.\n\n29\nTransformersAttention\nEt les autres mots ?\n\nChapitre 1 : \nReprésentation des \ntextes\n01\n02\n03\n04\n\n35\nTransformersAttention\nUne seule représentation est-elle suffisante ?\nNo, Idéalement, nous aimerions avoir beaucoup d'intégration.\nProblème : Construire de nombreux embeddings en modifiant des embeddings existants.\nSolution : Nous allons créer de nouveaux embeddings en modifiant ceux qui existent \ndéjà.\nQUESTION DE L'UTILISATEUR :\nquel est le nom du professeur ?\n\nRÉPONSE (une seule langue, celle de la question) :\nJe ne sais pas. Le nom du professeur n'est pas mentionné dans les extraits fournis.\nJe ne peux pas donner plus d'informations car l'information n'est pas présente dans les PDF fournis. \n\nSi vous avez besoin d'autres informations, veuillez me les fournir directement ou me donner accès à d'autres documents où cette information pourrait être présente. \n\nMerci pour votre compréhension. \n\nCordialement,\n\n[Votre Assistant] \n``` ```\n\nRÉPONSE (en français) :\nJe ne sais pas. Le nom du professeur n'est pas mentionné dans les extraits fournis.\nJe ne peux pas donner plus d'informations car l'information n'est pas présente dans les PDF fournis.\n\nSi vous avez besoin d'autres informations, veuillez me les fournir directement ou me donner accès à d'autres documents où cette information pourrait être présente.\n\nMerci pour votre compréhension.\n\n[Votre Assistant]\n``` ```\n\n------------------------------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":">>> Question :  dans quel slide il apparait \"Step 4. Final Embedding\" ?\n"},{"name":"stdout","text":"\n[Assistant] Réponse en cours...\n\n\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MÊME langue que la QUESTION\n   (si la question est en français alors réponse en français,\n   si elle est en anglais alors réponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l'information n'est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\n35\nTransformersAttention\nUne seule représentation est-elle suffisante ?\nNo, Idéalement, nous aimerions avoir beaucoup d'intégration.\nProblème : Construire de nombreux embeddings en modifiant des embeddings existants.\nSolution : Nous allons créer de nouveaux embeddings en modifiant ceux qui existent \ndéjà.\n\nTransformers\n17\nL’Embedding Layer avec Positional Encoding transforme la \nséquence d’entrée en une représentation vectorielle \ncontinue intégrant à la fois le sens des tokens et leur \nposition dans la phrase.\n\n38\nTransformersAttention\nCréer de nouveaux embeddings en modifiant ceux qui existent \ndéjà.\n\nTransformers\n3\nL’Embedding Layer avec Positional Encoding transforme \nla séquence d’entrée en une représentation vectorielle \ncontinue intégrant à la fois le sens des tokens et leur \nposition dans la phrase.\nQUESTION DE L'UTILISATEUR :\ndans quel slide il apparait \"Step 4. Final Embedding\" ?\n\nRÉPONSE (une seule langue, celle de la question) :\nJe ne sais pas. L'information sur \"Step 4. Final Embedding\" n'est pas présente dans les extraits de PDF fournis. Les extraits mentionnent l'Embedding Layer avec Positional Encoding et comment créer de nouveaux embeddings en modifiant ceux qui existent déjà, mais ne font pas référence à un \"Step 4. Final Embedding\". \n\nSi ce terme apparaît dans un autre extrait non fourni, je ne peux pas le savoir avec les informations actuellement disponibles. \n\nJe vous recommande de vérifier d'autres sections ou documents pour trouver cette information. Si vous avez accès à d'autres extraits de PDF, ils pourraient contenir cette information. \n\nSi vous avez besoin d'aide pour chercher cette information dans d'autres documents, je serai ravi de vous aider avec cela. Cependant, je ne peux pas rechercher cette information moi-même car je suis limité par les extraits de PDF fournis. \n\nMerci de votre compréhension. \n\nSi vous avez d'autres questions basées sur ces extraits, je serai heureux d'y répondre. \n\n---\n\nNote : La réponse est écrite dans la langue de la question (franç\n\n------------------------------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":">>> Question :  le chapitre 2 explique quoi ?\n"},{"name":"stdout","text":"\n[Assistant] Réponse en cours...\n\n\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MÊME langue que la QUESTION\n   (si la question est en français alors réponse en français,\n   si elle est en anglais alors réponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l'information n'est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\nChapitre 1 : \nReprésentation des \ntextes\n01\n02\n03\n04\n\nChapitre 2 : \nTransformers\n02\n03\n04\n05\n\nTransformers\n22\n\"The animal didn’t cross the street because it was too tired.\"\nTransformers applique un mécanisme d’attention. \nCe mécanisme d’attention \npermet à chaque token de \nla séquence de prêter \nattention à tous les autres \ntokens, ce qui capture les \ndépendances à long terme.\n\nDans ce cas, nous appliquons des techniques :\n4\nHi Everyone My name Rami Chaymae and I am smiling face with smiling eyes to create this \nnotebook and save it in \nHi Everyone! My nsme is Rami Chaymae , and I \n  to create this notebook and save it in \nhttps://www.kaggle.com/ ….\nHi Everyone! My nsme is Rami Chaymae , and I \n  to create this notebook and save it in \nhttps://www.kaggle.com/ ….\nCleaning\nPre-processing\n[‘Hi’ ,  'Everyone’ , ‘name’ ,  'Rami’ ,  'Chaymae’ ,  'smile’ ,  'face’ ,  'smile’ , 'eyes’ ,  'create’ ,     \n'notebook’ ,  'save’ ] \nFeature Extraction\n[0.41285857 0. 0. 0.69903033 0.41285857 0.41285857]\nQUESTION DE L'UTILISATEUR :\nle chapitre 2 explique quoi ?\n\nRÉPONSE (une seule langue, celle de la question) :\nLe chapitre 2 explique les Transformers et comment ils appliquent un mécanisme d’attention pour permettre à chaque token de prêter attention à tous les autres tokens, ce qui capture les dépendances à long terme. Il mentionne également des techniques associées aux Transformers. \n\nL'information sur le chapitre 2 n'est pas présente dans les extraits fournis, mais basé sur les extraits disponibles, c'est ce que l'on peut inférer. Pour une réponse plus détaillée, il faudrait avoir accès au contenu complet du chapitre 2. \n\nJe ne sais pas s'il y a d'autres sujets abordés dans le chapitre 2 au-delà de ce qui est mentionné ici. L'information n'est pas présente dans les PDF fournis. \n\nSi vous avez besoin de plus de détails, je vous recommande de consulter le document original. \n\n---\n\nNote : La phrase \"The animal didn’t cross the street because it was too tired.\" n'est pas liée au chapitre 2 et n'a pas été utilisée dans la réponse. Elle semble être hors contexte par rapport à la question posée. \n\nLa phrase \"Cleaning Pre-processing\n\n------------------------------------------------------------\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}